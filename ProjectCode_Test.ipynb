{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectCode-Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchristiaan/TrainCNN4SignatureVerification/blob/master/ProjectCode_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2hAm41ZiJ93b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please note that:\n",
        "#     # - Means comment explaining the code\n",
        "#     ### - Means things that need to be addressed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7kJiXaKFZTT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import all required repositories for the project\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import applications\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense, Input,concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model, model_from_json\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGmO3bqbF-qC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the google drive to upload the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-b0S5PwGEA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unzip the image dataset\n",
        "!unzip '/content/drive/Team Drives/inputdataset/UTSig.zip' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9v4c7wDVGgri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# File paths of the image data used later in the project\n",
        "gentr=\"/content/.....\"\n",
        "forgtr=\"/content/.....\"\n",
        "\n",
        "gent=\"/content/...\"\n",
        "forgt=\"/content/...\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wyIC4D10G1tB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Code block for working with the image files (resizing, retreiving files, etc.)\n",
        "\n",
        "# Standard height weight for images\n",
        "img_width, img_height, channels = 224, 224, 3\n",
        "\n",
        "dim = (img_width, img_height)\n",
        "\n",
        "### Do we need this??? ###\n",
        "def to_rgb(img):\n",
        "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) \n",
        "    img_rgb = np.asarray(np.dstack((img, img, img)), dtype=np.uint8)\n",
        "    return img_rgb\n",
        "\n",
        "\n",
        "# Takes in file patch and image name and returns resized image\n",
        "def returnimages(path,img):\n",
        "    image=cv2.imread(path+\"/\"+ img)                  #bringing the image\n",
        "    image=cv2.resize(image, (img_width, img_height))\n",
        "    image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image=to_rgb(image).reshape(1,img_width, img_height,3)/255.0       #resizing and normalizing    \n",
        "    return image     \n",
        "\n",
        "# Takes in number of author, path for genuine and forged signatures\n",
        "# Returns one image name (m.pop()), and two arrays of file names n = forgary, m = genuine\n",
        "# Used for generator()\n",
        "def getfiles(num,gen,forg):\n",
        "    a=os.listdir(gen)\n",
        "    b=os.listdir(forg)\n",
        "    c=str(num)\n",
        "    c=c[2:]\n",
        "    if(len(c)==2):\n",
        "        c=c+\"0\"\n",
        "        \n",
        "### This code needs to be altered ###  \n",
        "    n,m=[],[]\n",
        "    for i in b:\n",
        "        if i.endswith(c+\".png\"):\n",
        "            n=n+[i]\n",
        "        elif i.endswith(c+\".PNG\"):\n",
        "            n=n+[i]\n",
        "    for i in a:\n",
        "        if i.endswith(c+\".png\"):\n",
        "            m=m+[i]\n",
        "        elif i.endswith(c+\".PNG\"):\n",
        "            m=m+[i]\n",
        "    return m.pop(),n,m\n",
        "######################################\n",
        "\n",
        "### Needs to be looked into ###\n",
        "### used for generator2()   ###\n",
        "def getfiles2(num):\n",
        "    a=os.listdir(gentr)\n",
        "    b=os.listdir(forgtr)\n",
        "    c=str(num)\n",
        "    c=c[2:]\n",
        "    if(len(c)==2):\n",
        "        c=c+\"0\"\n",
        "### Needs to be altered ###\n",
        "    n,m=[],[]\n",
        "    for i in b:\n",
        "        if (i.endswith(c+\"_001_6g.png\") or i.endswith(c+\"_002_6g.png\") or i.endswith(c+\"_003_6g.png\")\n",
        "            or i.endswith(c+\"_004_6g.png\") or i.endswith(c+\"_005_6g.png\")):\n",
        "            n=n+[i]\n",
        "        elif (i.endswith(c+\"_001_6g.PNG\") or i.endswith(c+\"_002_6g.PNG\") or i.endswith(c+\"_003_6g.PNG\")\n",
        "              or i.endswith(c+\"_004_6g.PNG\") or i.endswith(c+\"_005_6g.PNG\")):\n",
        "            n=n+[i]\n",
        "    for i in a:\n",
        "        if (i.endswith(c+\"_001_6g.png\") or i.endswith(c+\"_002_6g.png\") or i.endswith(c+\"_003_6g.png\")\n",
        "            or i.endswith(c+\"_004_6g.png\") or i.endswith(c+\"_005_6g.png\")):\n",
        "            m=m+[i]\n",
        "        elif (i.endswith(c+\"_001_6g.PNG\") or i.endswith(c+\"_002_6g.PNG\") or i.endswith(c+\"_003_6g.PNG\")\n",
        "              or i.endswith(c+\"_004_6g.PNG\") or i.endswith(c+\"_005_6g.PNG\")):\n",
        "            m=m+[i]\n",
        "    return m.pop(),n,m\n",
        "#################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCNG0WU8IY8P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function for defining loss variable in model, leave for now, look into altering?\n",
        "# Unsure what y_pred is doing, or how this works....\n",
        "def triplet_loss(y_true, y_pred):\n",
        "    alpha = 0.5\n",
        "    anchor, positive, negative =y_pred[0,0:512], y_pred[0,512:1024], y_pred[0,1024:1536]\n",
        "    \n",
        "    positive_distance = K.mean(K.square(anchor - positive),axis=-1)\n",
        "    negative_distance = K.mean(K.square(anchor - negative),axis=-1)\n",
        "    return K.mean(K.maximum(0.0, positive_distance - negative_distance + alpha))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PDwiO2mI9KM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining the architecture. chose to go with 16 as it is smaller...\n",
        "model = applications.vgg16.VGG16(weights='imagenet', include_top=False, pooling='max')\n",
        "\n",
        "### Imput baseline model ### Unsure how this is done, commenting for now\n",
        "#basemodel = applications.vgg16.VGG16(weights='imagenet', include_top=False, pooling='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mIeOyITJa84",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For layers from 1 to 15 freeze the weights\n",
        "### We will need to do a test for each layer to find the optimal transfer* ###\n",
        "### For now just copying over the code from example\n",
        "for layer in model.layers[:15]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}